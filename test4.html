<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice-Controlled Box Movement</title>
  <style>
    .square {
      width: 100px;
      height: 100px;
      position: absolute;
      transition: top 0.1s ease-in-out;
      bottom: 0%;
    }
    #top-square {
      background-color: #3498db;
      transform: translateY(-100px);
    }
    #bottom-square {
      background-color: #e74c3c;
    }
  </style>
</head>
<body>

  <div id="top-square" class="square"></div>
  <div id="bottom-square" class="square"></div>

  <script>
    const topSquare = document.getElementById('top-square');
    const maxHeight = 50;  // Maximum upward movement in percentage (0-100%)

    // Set up Web Audio API
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;  // Set analyzer FFT size (this defines frequency resolution)
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    // Wait for user interaction to start the audio context
    document.body.addEventListener('click', () => {
      if (audioContext.state === 'suspended') {
        audioContext.resume();
        console.log("AudioContext resumed");
      }
    });

    // Request access to the microphone
    navigator.mediaDevices.getUserMedia({ audio: true })
      .then(stream => {
        console.log("Microphone access granted.");
        const source = audioContext.createMediaStreamSource(stream);
        source.connect(analyser);
        monitorAudio();
      })
      .catch(error => {
        console.error('Error accessing microphone:', error);
      });

    // Function to monitor audio levels and move the square based on volume
    function monitorAudio() {
      analyser.getByteTimeDomainData(dataArray);  // Get waveform data from the audio stream

      let sum = 0;
      // Calculate the average loudness by checking the amplitude of the waveform
      for (let i = 0; i < bufferLength; i++) {
        sum += Math.abs(dataArray[i] - 128);  // Get the absolute difference from the midpoint (128)
      }

      // Normalize the loudness (average value) to a range of 0 to 1
      const averageLoudness = sum / bufferLength;
      const normalizedLoudness = averageLoudness / 128; // Normalize to a 0-1 scale (128 is the middle value)

      // Increase sensitivity by multiplying by 100
      const movement = normalizedLoudness * maxHeight * 0.25;  // Increase the movement by 100 times

      // Log the loudness and movement values for debugging
      console.log("Loudness:", normalizedLoudness, "Movement:", movement);

      // Move the top square according to the loudness (negative values move it up)
      topSquare.style.bottom = `${movement}%`;  // Move the square upwards based on loudness

      // Continue monitoring the audio
      requestAnimationFrame(monitorAudio);
    }
  </script>

</body>
</html>
